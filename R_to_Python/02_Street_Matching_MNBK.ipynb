{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41b5e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from fuzzymatcher import link_table, fuzzy_left_join\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13636848/is-it-possible-to-do-fuzzy-match-merge-with-python-pandas\n",
    "\n",
    "# This website lists out many functions/packages similar to fuzzyjoin in R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44fd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_addresses = pd.DataFrame(np.array([[1, 2], [4, 5], [7, 8]]),\n",
    "                   columns=['a', 'b'])\n",
    "cleaned = np.repeat(np.nan, len(unique_addresses))\n",
    "cleaned[2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d91d9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#02_Street_Matching_MNBK.R: [function] does address matching using Street Dictionary and filling down.\n",
    "\n",
    "def street_match(sample, edict):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    -------\n",
    "    'sample': Census sample to match. Note: this is currently tailored to samples that have same columns as the original 100k sample. If column names change, adapt the code to clean column names accordingly, ensuring that relevant column names retain the names specified in the function.\n",
    "    'edict': Street Dictionary used for matching. Ensure that each ED is a row and streets in the ED are in columns.\n",
    "    \n",
    "    outputs:\n",
    "    -------\n",
    "    The full, original census sample data input into the function with 3 additional columns: \n",
    "    best_match: Column containing best street name match\n",
    "    result_type: 1 of 6 possible match types: (1) Perfect Match, (2) Identical Match, (3) Singular Mode, (4) Multiple Modes, (5) NA mode, (6) No match. Refer to documentation for more details.\n",
    "    flag_st: Flag if street name match was ultimately obtained via fill down (which is the case for result type 4-6).\n",
    "    The original street name is stored in \\code{street_add}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # ---- FUNCTION ----\n",
    "    \n",
    "    ## clean column names: adapt code if sample has different columns. At minimum, ensure `record`, `ED` and `street_add` columns exist after cleaning.\n",
    "    sample.columns = [\"record\", \"township\", \"county\", \"ED\", \"person_id\",\n",
    "                     \"dwelling_seq\", \"dwelling_ser\", \"dwelling_ser2\", \"hh_seq\", \"hh_seq_8\",\n",
    "                     \"hh_ser2\", \"hh_ser_bef_split\", \"indiv_seq\", \"split\", \n",
    "                     \"line_no\", \"line_no2\", \"microfilm\",\n",
    "                     \"n_fam\", \"n_person_bef_split\", \"house_num\", \"street_add\"]\n",
    "    \n",
    "    ## clean ED number\n",
    "    edict.ED = edict.ED.rjust(4, \"0\")\n",
    "    \n",
    "    ## Extract Unique Addresses\n",
    "    unique_addresses = sample[sample.street_add.notna()][['ED','street_add']].unique()\n",
    "    \n",
    "    # ---- CLEAN ADDRESSES ----\n",
    "    ## import rem_dup_word - remove duplicate words\n",
    "    def rem_dup_word(x):\n",
    "        x = x.lower()\n",
    "        new_x = ' '.join(np.unique(x.split().strip()))\n",
    "        return new_x\n",
    "    \n",
    "    ## [NOTE] make sure to run clean() function from '01_Street_Clean_Function_MNBK.R'\n",
    "    \n",
    "    ## preallocate memory for cleaned column \n",
    "    # cleaned <- rep(NA_character_, nrow(unique_addresses))\n",
    "    cleaned = np.repeat(np.nan, len(unique_addresses))\n",
    "    \n",
    "    ## apply rem_dup_word() and str_clean()\n",
    "    for i in 1:len(unique_addresses):\n",
    "#         cleaned[i] = clean(unique_addresses.iloc[i, 2].apply(lambda x: rem_dup_word(str(x))).upper())\n",
    "        \n",
    "        cleaned[i] = unique_addresses.iloc[i, 2].apply(lambda x: rem_dup_word(str(x))).upper() \n",
    "        cleaned[i] = clean(cleaned[i])\n",
    "    \n",
    "    # ---- FIRST MATCH ----\n",
    "    ## create add_matches, which combines `unique_addresses` with the `cleaned` column\n",
    "    add_matches = unique_addresses[['ED', 'street_add']]\n",
    "    add_matches['cleaned'] = cleaned\n",
    "      \n",
    "    ## create str_algo, which has all the methods we will use\n",
    "    str_algo = [\"dl\", \"qgram\", \"cosine\", \"jaccard\", \"jw\"]\n",
    "\n",
    "    ## create empty lists which will store outputs\n",
    "    algo_list = list()\n",
    "    ed_list = list()\n",
    "    \n",
    "    for i in add_matches.ED.unique():\n",
    "        # create subset of edict and add_matches for a particular ED\n",
    "        # TO ACCEPT BK: ED_dict <- filter(edict, ED == i & MNBK == \"BK\") %>%\n",
    "        ED_dict = edict[edict['ED'] == i].dropna()\n",
    "        ED_add = add_matches[add_matches['ED'] == i]\n",
    "        \n",
    "        for j in str_algo:\n",
    "            # stringdist_join, extract best match for each method\n",
    "            result = ED_add.merge(ED_dict, how = 'left', on = 'clean')\n",
    "            result = result[['ED', 'raw', 'clean.x', 'clean.y', 'dscore']].groupby(by = 'raw').sort_values(by='dscore').iloc[0,:]\n",
    "            \n",
    "        # at this point, result = dataframe of addresses in ED (i), merged with method (j)\n",
    "        # append result to algo_list, each element in algo_list is a dataframe\n",
    "        algo_list[[j]] = result\n",
    "\n",
    "        # \"column bind\" all elements in algo_list to form a df called ed_df\n",
    "        # ed_df now contains all addresses in ED(i) with matches using all methods\n",
    "        \n",
    "        ed_df = algo_list[[\"ED\", \"raw\", \"clean.x\"]]\n",
    "\n",
    "        ed_list[i] = ed_df\n",
    "        \n",
    "    ## bind all dfs by row\n",
    "    match_dict = ed_list[['ED', 'raw']]\n",
    "    match_dict['clean'] = clean.x\n",
    "    match_dict['match_dl'] = clean.y.x\n",
    "    match_dict['match_qgram'] = clean.y.y\n",
    "    match_dict['match_cos'] = clean.y.x.x\n",
    "    match_dict['match_jac'] = clean.y.y.y\n",
    "    match_dict['match_jw'] = clean.y\n",
    "    match_dict['dscore_dl'] = dscore.x\n",
    "    match_dict['dscore_qgram'] = dscore.y\n",
    "    match_dict['dscore_cos'] = dscore.x.x\n",
    "    match_dict['dscore_jac'] = dscore.y.y\n",
    "    match_dict['dscore_jw'] = dscore\n",
    "    \n",
    "#     match_dict <- bind_rows(ed_list) %>%\n",
    "#     select(ED = ED, raw = raw, clean = clean.x,\n",
    "#            match_dl = clean.y.x, dscore_dl = dscore.x,\n",
    "#            match_qgram = clean.y.y, dscore_qgram = dscore.y,\n",
    "#            match_cos = clean.y.x.x, dscore_cos = dscore.x.x,\n",
    "#            match_jac = clean.y.y.y, dscore_jac = dscore.y.y,\n",
    "#            match_jw = clean.y, dscore_jw = dscore)\n",
    "    \n",
    "    # ---- FURTHER TUNING ----\n",
    "    # create summary statistics\n",
    "    \n",
    "    summ_dscores = match_dict[['match_dl', 'match_qgram', 'match_cos', 'match_jac', 'match_jw', 'dscore_dl', 'dscore_qgram', 'dscore_cos', 'dscore_jac', 'dscore_jw']].fillna('5')\n",
    "    summ_dscores.groupby('ED').agg({'dscore_dl':['mean', 'std'],\n",
    "                                    'dscore_qgram':['mean', 'std'], \n",
    "                                    'dscore_cos':['mean', 'std'], \n",
    "                                    'dscore_jac':['mean', 'std']}).fillna('0').reset_index(inplace = True)\n",
    "    \n",
    "#     summ_dscores <- match_dict %>%\n",
    "#     mutate(match_dl = ifelse(is.na(match_dl), \"5\", match_dl),\n",
    "#            match_qgram = ifelse(is.na(match_qgram), \"5\", match_qgram),\n",
    "#            match_cos = ifelse(is.na(match_cos), \"5\", match_cos),\n",
    "#            match_jac = ifelse(is.na(match_jac), \"5\", match_jac),\n",
    "#            match_jw = ifelse(is.na(match_jw), \"5\", match_jw),\n",
    "#            dscore_dl = ifelse(is.na(dscore_dl), 5, dscore_dl),\n",
    "#            dscore_qgram = ifelse(is.na(dscore_qgram), 5, dscore_qgram),\n",
    "#            dscore_cos = ifelse(is.na(dscore_cos), 5, dscore_cos),\n",
    "#            dscore_jac = ifelse(is.na(dscore_jac), 5, dscore_jac),\n",
    "#            dscore_jw = ifelse(is.na(dscore_jw), 5, dscore_jw)) %>%\n",
    "#     group_by(ED) %>%\n",
    "#     summarize(mean_dl = mean(dscore_dl), sd_dl = sd(dscore_dl),\n",
    "#               mean_qgram = mean(dscore_qgram), sd_qgram = sd(dscore_qgram),\n",
    "#               mean_cos = mean(dscore_cos), sd_cos = sd(dscore_cos),\n",
    "#               mean_jac = mean(dscore_jac), sd_jac = sd(dscore_jac),\n",
    "#               mean_jw = mean(dscore_jw), sd_jw = sd(dscore_jw)) %>%\n",
    "#     replace(is.na(.), 0)\n",
    "    \n",
    "    # format into a list such that e.g. `summ_dscores_list$0010$jw$mean` gives mean jw dscore of ED 0010\n",
    "    summ_dscores_list = list(summ_dscores.ED.unique())\n",
    "    \n",
    "#     summ_dscores_list <- unique(summ_dscores$ED) %>% as.list()\n",
    "#     names(summ_dscores_list) <- unique(summ_dscores$ED)\n",
    "\n",
    "    for i in summ_dscores_list:\n",
    "        s = summ_dscores[summ_dscores['ED'] == i]\n",
    "        ED_sum_list = list({'dl': s.mean_dl, 'sd':s.sd_dl}, {'qgram': s.mean_qgram})\n",
    "        \n",
    "        summ_dscores_list[[i]] = ED_sum_list\n",
    "#     for (i in names(summ_dscores_list)) {\n",
    "#     s <- filter(summ_dscores, ED == i)\n",
    "#     ED_sum_list <- list(dl = list(mean = s$mean_dl, sd = s$sd_dl),\n",
    "#                         qgram = list(mean = s$mean_qgram, sd = s$sd_qgram),\n",
    "#                         cosine = list(mean = s$mean_cos, sd = s$sd_cos),\n",
    "#                         jaccard = list(mean = s$mean_jac, sd = s$sd_jac),\n",
    "#                         jw = list(mean = s$mean_jw, sd = s$sd_jw))\n",
    "#     summ_dscores_list[[i]] <- ED_sum_list\n",
    "#   }\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # match again\n",
    "    for i in add_matches.ED.unique():\n",
    "        ED_dict = edict[edict['ED'] == i]\n",
    "        \n",
    "        ED_add = add_matches[add_matches['ED'] == i]\n",
    "        \n",
    "        for j in str_algo:\n",
    "            threshold = summ_dscores_list[[i][j]].mean + 2*summ_dscores_list[[i]][[j]].sd\n",
    "            result = ED_add.merge(ED_dict, how = 'left', on = 'clean')\n",
    "            result = result[['ED', 'raw', 'clean.x', 'clean.y', 'dscore']].groupby(by = 'raw')\n",
    "            \n",
    "            algo_list[[j]] = result\n",
    "            ef_df = algo_list\n",
    "        \n",
    "        ed_list[[i]] = ed_df\n",
    "    \n",
    "#     for (i in unique(add_matches$ED)) {\n",
    "#     # create subset of edict and add_matches for a particular ED\n",
    "#     # TO ACCEPT BK: ED_dict <- filter(edict, ED == i & MNBK == \"BK\") %>%\n",
    "#     ED_dict <- filter(edict, ED == i) %>% \n",
    "#       select(- \"ED\") %>%\n",
    "#       unlist() \n",
    "#     ED_dict <- data.frame(clean = ED_dict, stringsAsFactors = FALSE) %>%\n",
    "#       filter(!is.na(clean))\n",
    "#     ED_add <- filter(add_matches, ED == i)\n",
    "    \n",
    "#     for (j in str_algo) {\n",
    "#       # set a max_dist that varies by ED. max_dist is 2sd higher than mean.\n",
    "#       threshold <- summ_dscores_list[[i]][[j]]$mean + 2 * summ_dscores_list[[i]][[j]]$sd\n",
    "      \n",
    "#       # stringdist_join, extract best match for each method\n",
    "#       result <- stringdist_left_join(ED_add, ED_dict, by = \"clean\", \n",
    "#                                      max_dist = threshold, method = j, distance_col = \"dscore\") %>%\n",
    "#         select(ED, raw, clean.x, clean.y, dscore) %>%\n",
    "#         group_by(raw) %>%\n",
    "#         arrange(dscore) %>%\n",
    "#         slice(1)\n",
    "      \n",
    "#       # at this point, result = dataframe of addresses in ED (i), merged with method (j)\n",
    "#       # append result to algo_list, each element in algo_list is a dataframe\n",
    "#       algo_list[[j]] <- result\n",
    "      \n",
    "#       # \"column bind\" all elements in algo_list to form a df called ed_df\n",
    "#       # ed_df now contains all addresses in ED(i) with matches using all methods\n",
    "#       ed_df <- algo_list %>% \n",
    "#         reduce(left_join, by = c(\"ED\", \"raw\", \"clean.x\"))\n",
    "#     }\n",
    "#     # append each ed_df to ed_list \n",
    "#     ed_list[[i]] <- ed_df\n",
    "#   }\n",
    "\n",
    "\n",
    "    ## bind all dfs by row\n",
    "    match_dict = ed_list[['ED', 'raw']]\n",
    "    match_dict['clean'] = clean.x\n",
    "    match_dict['match_dl'] = clean.y.x\n",
    "    match_dict['match_qgram'] = clean.y.y\n",
    "    match_dict['match_cos'] = clean.y.x.x\n",
    "    match_dict['match_jac'] = clean.y.y.y\n",
    "    match_dict['match_jw'] = clean.y\n",
    "    match_dict['dscore_dl'] = dscore.x\n",
    "    match_dict['dscore_qgram'] = dscore.y\n",
    "    match_dict['dscore_cos'] = dscore.x.x\n",
    "    match_dict['dscore_jac'] = dscore.y.y\n",
    "    match_dict['dscore_jw'] = dscore\n",
    "    \n",
    "#     match_dict <- bind_rows(ed_list) %>%\n",
    "#     select(ED = ED, raw = raw, clean = clean.x,\n",
    "#            match_dl = clean.y.x, dscore_dl = dscore.x,\n",
    "#            match_qgram = clean.y.y, dscore_qgram = dscore.y,\n",
    "#            match_cos = clean.y.x.x, dscore_cos = dscore.x.x,\n",
    "#            match_jac = clean.y.y.y, dscore_jac = dscore.y.y,\n",
    "#            match_jw = clean.y, dscore_jw = dscore)\n",
    "    \n",
    "    # ---- BEST MATCH ----\n",
    "    # function to extract modes\n",
    "    \n",
    "    def modal(x):\n",
    "        freq = pd.DataFrame(x.size())\n",
    "        result = \n",
    "        \n",
    "        if len(result) > 1:\n",
    "            result = \"+\".join(result)\n",
    "        \n",
    "        return result\n",
    "       \n",
    "#     modal <- function(x) {\n",
    "#     freq <- table(x) %>% as.data.frame(stringsAsFactors = FALSE)\n",
    "#     result <- freq[which(freq$Freq == max(freq$Freq)), 1]\n",
    "#     if (length(result) > 1){\n",
    "#       result <- str_c(result, collapse = \"+\")\n",
    "#     }\n",
    "#     result\n",
    "#   }\n",
    "    \n",
    "    # extract modes\n",
    "    match_dict[['match_dl', 'match_qgram', 'match_cos', 'match_jac', 'match_jw', 'dscore_dl', 'dscore_qgram', 'dscore_cos', 'dscore_jac', 'dscore_jw']].fillna('0')\n",
    "    match_dict_modes = match_dict[['ED', 'raw', 'clean', 'match_dl', 'match_qgram', 'match_cos', 'match_jac', 'match_jw']]\n",
    "    \n",
    "    \n",
    "#     match_dict_modes <- match_dict %>%\n",
    "#     mutate(match_dl = ifelse(is.na(match_dl), \"0\", match_dl),\n",
    "#            match_qgram = ifelse(is.na(match_qgram), \"0\", match_qgram),\n",
    "#            match_cos = ifelse(is.na(match_cos), \"0\", match_cos),\n",
    "#            match_jac = ifelse(is.na(match_jac), \"0\", match_jac),\n",
    "#            match_jw = ifelse(is.na(match_jw), \"0\", match_jw),\n",
    "#            dscore_dl = ifelse(is.na(dscore_dl), 0, dscore_dl),\n",
    "#            dscore_qgram = ifelse(is.na(dscore_qgram), 0, dscore_qgram),\n",
    "#            dscore_cos = ifelse(is.na(dscore_cos), 0, dscore_cos),\n",
    "#            dscore_jac = ifelse(is.na(dscore_jac), 0, dscore_jac),\n",
    "#            dscore_jw = ifelse(is.na(dscore_jw), 0, dscore_jw)) %>%\n",
    "#     select(ED, raw, clean, match_dl, match_qgram, \n",
    "#            match_cos, match_jac, match_jw) %>%\n",
    "#     gather(\"method\", \"match\", - c(\"ED\", \"raw\", \"clean\")) %>%\n",
    "#     group_by(ED, raw) %>%\n",
    "#     summarise(mode = modal(match))\n",
    "\n",
    "\n",
    "    # join to match_dict\n",
    "    match_dict = pd.merge(match_dict, match_dict_modes, how = 'left', on =['ED', 'raw'])\n",
    "#     match_dict <- left_join(match_dict, match_dict_modes, by = c(\"ED\", \"raw\"))\n",
    "\n",
    "    # best match\n",
    "    match_dict[['match_dl', 'match_qgram', 'match_cos', 'match_jac', 'match_jw', 'dscore_dl', 'dscore_qgram', 'dscore_cos', 'dscore_jac', 'dscore_jw']].fillna('0')\n",
    "           \n",
    "#     match_dict <- match_dict %>%\n",
    "#     mutate(match_dl = ifelse(is.na(match_dl), \"0\", match_dl),\n",
    "#            match_qgram = ifelse(is.na(match_qgram), \"0\", match_qgram),\n",
    "#            match_cos = ifelse(is.na(match_cos), \"0\", match_cos),\n",
    "#            match_jac = ifelse(is.na(match_jac), \"0\", match_jac),\n",
    "#            match_jw = ifelse(is.na(match_jw), \"0\", match_jw),\n",
    "#            dscore_dl = ifelse(is.na(dscore_dl), 0, dscore_dl),\n",
    "#            dscore_qgram = ifelse(is.na(dscore_qgram), 0, dscore_qgram),\n",
    "#            dscore_cos = ifelse(is.na(dscore_cos), 0, dscore_cos),\n",
    "#            dscore_jac = ifelse(is.na(dscore_jac), 0, dscore_jac),\n",
    "#            dscore_jw = ifelse(is.na(dscore_jw), 0, dscore_jw)) %>%\n",
    "#     rowwise() %>%\n",
    "#     mutate(result_type = ifelse(match_dl == match_cos & match_dl == match_qgram & match_dl == match_jac & match_dl == match_jw, ifelse(clean == match_dl, 1, ifelse(mode == 0, 6, 2)), ifelse(str_detect(mode, \"\\\\+\"), 4, ifelse(mode == 0, 5, 3)))) %>%\n",
    "#     mutate(best_match = case_when(result_type %in% c(1, 2, 3) ~ mode,\n",
    "#                                   result_type %in% c(4, 5, 6) ~ \"0\"))\n",
    "    \n",
    "    \n",
    "    # ---- FILL DOWN ----\n",
    "    # create flags for row that had to be filled\n",
    "    match_dict = np.where(match_dict.best_match == 0, 1, 0)\n",
    "    match_dict\n",
    "    na_matches = match_dict[match_dict['best_match'] == 0]\n",
    "    \n",
    "#     match_dict <- mutate(match_dict, flag = ifelse(best_match == 0, 1, 0))\n",
    "#     match_dict$index <- 1:nrow(match_dict)\n",
    "  \n",
    "#     na_matches <- filter(match_dict, best_match == 0)\n",
    "\n",
    "\n",
    "    # fill down\n",
    "    \n",
    "    for i in na_matches.index:\n",
    "        \n",
    "        match_ED = na_matches[na_matches.index == i]['ED']\n",
    "        \n",
    "        \n",
    "    \n",
    "# for (i in na_matches$index) {\n",
    "#     # extract pool of potential matches\n",
    "#     i <- as.numeric(i)\n",
    "#     match_ED <- na_matches[na_matches$index == i, \"ED\"]\n",
    "#     pool_indexes <- c(i - 3, i - 2, i - 1, i + 1, i + 2, i + 3)\n",
    "#     pool_matches <- filter(match_dict, index %in% pool_indexes & ED == match_ED) %>%\n",
    "#       select(best_match) %>%\n",
    "#       distinct()\n",
    "    \n",
    "        # match using jw\n",
    "        match = \n",
    "        \n",
    "#         match <- stringdist_left_join(filter(na_matches, index == i), pool_matches, by = c(clean = \"best_match\"), \n",
    "#                                       max_dist = 5, method = \"jw\", distance_col = \"dscore\") %>%\n",
    "#           group_by(raw) %>%\n",
    "#           arrange(dscore) %>%\n",
    "#           slice(1)\n",
    "    \n",
    "    # sub match into match_dict\n",
    "    match_dict[match_dict.index == i]['best_match'] = match['best_match.y']\n",
    "#     match_dict[match_dict$index == i, \"best_match\"] <- match$best_match.y\n",
    "#   }\n",
    "\n",
    "    # ---- MERGE TO ORIGINAL SAMPLE ----\n",
    "    match_dict_subset = match_dict[[]]\n",
    "    sample_cleaned = pd.merge(sample, match_dict_subset, how = 'left', left_on = [\"ED\", \"ED\"], right_on = [\"street_add\", \"raw\"])\n",
    "    \n",
    "#   match_dict_subset <- select(match_dict, ED, raw, best_match, result_type, flag_st = flag)\n",
    "#   sample_cleaned <- left_join(sample, match_dict_subset, by = c(\"ED\" = \"ED\", \"street_add\" = \"raw\"))\n",
    "# }\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
